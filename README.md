# Bacterial GAN Augmentation

A deep learning project for bacterial image augmentation using **StyleGAN2-ADA** to generate synthetic Gram-positive and Gram-negative bacterial images for improved classification.

## ğŸ¯ Overview

This project uses StyleGAN2-ADA (Adaptive Discriminator Augmentation) to generate realistic synthetic bacterial images, specifically designed for:
- Limited data scenarios common in medical imaging
- Class-conditional generation (Gram-positive vs Gram-negative)
- Resource-constrained training (optimized for <16GB VRAM)

## ğŸ—ï¸ Architecture

### StyleGAN2-ADA
- **Mapping Network**: Transforms z â†’ w latent space for better disentanglement
- **Synthesis Network**: Style-modulated image generation at 256Ã—256 resolution
- **Discriminator**: With Adaptive Discriminator Augmentation (ADA)
- **Class Conditioning**: Via projection discriminator and class embeddings

### Key Features
- **ADA**: Dynamically adjusts augmentation to prevent discriminator overfitting
- **R1 Regularization**: Gradient penalty for stable training
- **Lazy Regularization**: Efficient computation (R1 every 16 steps)
- **Simplified Mode**: For GPUs with <16GB VRAM

## ğŸš€ Quick Start

```bash
# Installation
git clone <repository-url>
cd bacterial-gan-augmentation
poetry install

# Prepare data
# Place images in: data/01_raw/gram_positive/ and data/01_raw/gram_negative/
poetry run python scripts/prepare_data.py

# Training
bacterial-gan train

# Generate synthetic data
bacterial-gan generate-data --run-id <mlflow-run-id> --num-images 1000

# Run API
make run-api
```

## ğŸ“ Project Structure

```
bacterial-gan-augmentation/
â”œâ”€â”€ src/bacterial_gan/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ stylegan2_ada.py      # Generator & Discriminator
â”‚   â”‚   â”œâ”€â”€ stylegan2_wrapper.py  # Training wrapper
â”‚   â”‚   â””â”€â”€ losses.py             # R1, path length, logistic loss
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ train_pipeline.py     # Training with MLflow
â”‚   â”‚   â”œâ”€â”€ evaluate_pipeline.py  # FID, IS, accuracy
â”‚   â”‚   â””â”€â”€ generate_data_pipeline.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py            # Data loading
â”‚   â”‚   â””â”€â”€ data_processing.py    # Patch extraction
â”‚   â””â”€â”€ config.py                 # Configuration
â”œâ”€â”€ app/                          # FastAPI application
â”œâ”€â”€ configs/config.yaml          # Training configuration
â”œâ”€â”€ scripts/                      # Utility scripts
â””â”€â”€ tests/                        # Unit tests
```

## âš™ï¸ Configuration

Key settings in `configs/config.yaml`:

```yaml
training:
  use_simplified: true       # For <16GB VRAM
  image_size: 256
  batch_size: 12
  epochs: 300
  learning_rate_g: 0.0002
  learning_rate_d: 0.0002
  
  # Regularization
  r1_gamma: 10.0
  r1_interval: 16
  
  # ADA
  use_ada: true
  ada_target: 0.6
```

## ğŸ“Š MLflow Tracking

All training runs are tracked with:
- **Parameters**: Architecture settings, hyperparameters
- **Metrics**: generator_loss, discriminator_loss, r1_penalty, ada_probability
- **Artifacts**: Sample images, checkpoints, final model

View experiments: `mlflow ui`

## ğŸ“ˆ Evaluation Metrics

- **FID Score**: Image quality measurement
- **Inception Score**: Diversity and quality
- **Classification Accuracy**: Downstream task performance

## ğŸ› ï¸ Development

```bash
# Format code
make format

# Lint
make lint

# Run tests
make test
```

## ğŸ“š References

- [StyleGAN2-ADA Paper](https://arxiv.org/abs/2006.06676)
- [StyleGAN2 Paper](https://arxiv.org/abs/1912.04958)

## ğŸ“„ License

MIT License
